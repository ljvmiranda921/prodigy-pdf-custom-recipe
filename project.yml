title: "Prodigy recipes for document processing and layout understanding"

directories:
  - "assets"
  - "dataset"
  - "model"

vars:
  dataset_name: funsd

assets:
  - dest: "assets/${vars.dataset_name}.zip"
    description: "FUNSD dataset - noisy scanned documents for layout understanding"
    url: https://guillaumejaume.github.io/FUNSD/dataset.zip

workflows:
  all:
    - "install"
    - "hydrate-db"
    - "train"
  clean-all:
    - "clean-db"
    - "clean-files"

commands:
  - name: "install"
    help: "Install dependencies"
    script:
      - "pip install --user -r requirements.txt"
      - "sudo apt install tesseract-ocr -y"

  - name: "hydrate-db"
    help: "Hydrate the Prodigy database with annotated data from FUNSD"
    script:
      - "python3 -m scripts.preprocess assets/${vars.dataset_name}.zip dataset/"
      - "python3 -m prodigy db-in-image ${vars.dataset_name} -F scripts/recipes/loaders.py"
    deps:
      - assets/${vars.dataset_name}.zip

  - name: "review"
    help: "Review hydrated annotations"
    script:
      - "python3 -m prodigy db-out ${vars.dataset_name} dataset"
      - >-
        python3 -m prodigy image.manual 
        ${vars.dataset_name}-debug 
        dataset/${vars.dataset_name}.jsonl 
        --loader jsonl 
        --label question,answer,header,other
    outputs:
      - dataset/funsd.jsonl

  - name: "train"
    help: "Train FUNSD model"
    script:
      - >-
        python3 -m prodigy train-image ${vars.dataset_name} model/
        -F scripts/recipes/train.py --verbose --eval
    output:
      - model/checkpoint-500/
      - model/checkpoint-1000/

  - name: "clean-db"
    help: "Drop all generated Prodigy datasets"
    script:
      - "prodigy drop ${vars.dataset_name}"
      - "prodigy drop ${vars.dataset_name}-debug"

  - name: "clean-files"
    help: "Clean all intermediary files"
    script:
      - "sh -c 'rm -rf assets/*'"
      - "sh -c 'rm -rf dataset/*'"
